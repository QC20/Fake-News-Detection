{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "GuM4rEOrVoCw"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "MvBssgEygZDO",
        "outputId": "25f1f289-c4be-4b05-80b3-37878c8ac4bc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        }
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.dummy import DummyClassifier\n",
        "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.feature_selection import SelectKBest, chi2, f_regression\n",
        "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier, ExtraTreesClassifier, GradientBoostingClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "import glob\n",
        "import os\n",
        "import zipfile\n",
        "from xml.etree import ElementTree as ET\n",
        "\n",
        "# Text proccessing\n",
        "import re\n",
        "\n",
        "from nltk.sentiment import SentimentIntensityAnalyzer\n",
        "from nltk.corpus import wordnet as wn\n",
        "from nltk import pos_tag, word_tokenize\n",
        "import nltk\n",
        "nltk.download('vader_lexicon')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('punkt')\n",
        "from nltk.corpus import stopwords"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/nltk/twitter/__init__.py:20: UserWarning: The twython library has not been installed. Some functionality from the twitter package will not be available.\n",
            "  warnings.warn(\"The twython library has not been installed. \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package vader_lexicon to /root/nltk_data...\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MhohirUS-HoL"
      },
      "source": [
        "# Text_Loading"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A0j0l-JukBmQ"
      },
      "source": [
        "with zipfile.ZipFile('./datasets/pan20-author-profiling-training-2020-02-23.zip', 'r') as zip_ref:\n",
        "  zip_ref.extractall('./datasets')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tbdgQKiEkmYV"
      },
      "source": [
        "data_path = './datasets/pan20-author-profiling-training-2020-02-23/'\n",
        "lang = 'en'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pC3A-OyTl6NG"
      },
      "source": [
        "labels_path = data_path + lang + '/truth.txt'\n",
        "true_values = {}\n",
        "\n",
        "file = open(labels_path)\n",
        "for line in file:\n",
        "    line_parsed = line.strip().split(':::')\n",
        "    true_values[line_parsed[0]] = line_parsed[1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W-ZkbeZF-K57"
      },
      "source": [
        "# Text_Proccessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eaAhPC4qlY1o"
      },
      "source": [
        "def get_tweets(file):\n",
        "  \"\"\"\n",
        "  Arguments:\n",
        "    file - file to proccess\n",
        "  Returns:\n",
        "    array of tweets\n",
        "  \"\"\"\n",
        "  tweets = []\n",
        "  parsed_file = ET.parse(file)\n",
        "  documents = parsed_file.iter('document')\n",
        "\n",
        "  for doc in documents:\n",
        "    tweets.append(clean_text(doc.text))\n",
        "\n",
        "  return tweets"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "08jiBsKILYWt"
      },
      "source": [
        "def clean_text(text):\n",
        "  \"\"\"\n",
        "  Arguments:\n",
        "    text: text to be parsed\n",
        "  Returns\n",
        "    text without special characters\n",
        "  \"\"\"\n",
        "  text = re.sub(r\"\\n\", \" \", text)\n",
        "  text = re.sub(r\"sp\", \" \", text)\n",
        "  # text = text.lower()\n",
        "  text = re.sub(r\"[^a-zA-Z ]\", \" \", text) # remove everything expect a-z\n",
        "  text = re.sub(r\"\\b\\w{1,1}\\b\", \" \",text) # remove everything of length 1\n",
        "  text = \" \".join([x for x in text.split()])\n",
        "  return text"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lrfJQ4K6xiZD"
      },
      "source": [
        "def get_tweets_representation(tweets):\n",
        "  \"\"\"\n",
        "  Arguments:\n",
        "    tweets: array of tweets\n",
        "  Returns:\n",
        "    array with string concatenation of tweets\n",
        "  \"\"\"\n",
        "  return np.array(np.array2string(np.array(tweets)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FPMwjx5zDeSd"
      },
      "source": [
        "def get_tweets_pos_tags(text):\n",
        "  \"\"\"\n",
        "  Arguments:\n",
        "    tweets: text\n",
        "  Returns:\n",
        "    dictionary pos\n",
        "  \"\"\"\n",
        "  return pos_tag(word_tokenize(text))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PmuwSBGRj6fr"
      },
      "source": [
        "def get_tweets_features(tweets):\n",
        "  \"\"\"\n",
        "  Arguments:\n",
        "    tweets - array of tweets\n",
        "  Returns:\n",
        "    mean tweet size\n",
        "  \"\"\"\n",
        "  tweet_lengths = [len(tweet) for tweet in tweets]\n",
        "  mean_tweet_length = np.mean(tweet_lengths)\n",
        "  std_tweet_length = np.std(tweet_lengths)\n",
        "  return [mean_tweet_length, std_tweet_length]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k18qL17dkZot",
        "outputId": "56883d5d-6355-4028-fac9-6e1126a69eb0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "X = []\n",
        "X_tweets = []\n",
        "X_pos = []\n",
        "X_extra = []\n",
        "y = []\n",
        "\n",
        "for file in glob.glob(data_path + lang + \"/*.xml\"):\n",
        "  user_code = file.split('/')[-1][:-4]\n",
        "  user_tweets = get_tweets(file)\n",
        "  user_tweets_representation = get_tweets_representation(user_tweets)\n",
        "  user_tweets_extra_features = get_tweets_features(user_tweets)\n",
        "\n",
        "  X.append(user_tweets_representation)\n",
        "  X_tweets.append(user_tweets)\n",
        "  X_extra.append(user_tweets_extra_features)\n",
        "  y.append(true_values[user_code])\n",
        "\n",
        "X = np.array(X)\n",
        "X_tweets = np.array(X_tweets)\n",
        "X_extra = np.array(X_extra)\n",
        "y = np.array(y)\n",
        "y = y.astype(np.float32)\n",
        "print(\"X shape: {} | X_extra shape: {} | y shape: {}\".format(X.shape, X_extra.shape, y.shape))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X shape: (300,) | X_extra shape: (300, 2) | y shape: (300,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vS715RnwK1ST",
        "outputId": "ae7cedc5-0ca9-4de9-92ed-42e260250fe2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "source": [
        "X[:2]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([\"['Justin Trudeau bows and shakes hands with Iranian foreign minister in photo op True North URL'\\n 'Can Moscow finish Nord Stream gas pipeline de ite US sanctions Never say never says Gazprom RT Business News URL'\\n 'KNIGHT Pipeline protests have nothing to do with supporting the Wet suwet en people True North URL'\\n 'From clothes to condoms Coronavirus is threatening global consumption in ways you never knew were possible RT Wo URL'\\n 'Amazon has job listings maybe its most ever URL'\\n 'NASA confirms SpaceX will become the first private company to send astronauts to the ace station URL'\\n 'More than former DOJ officials call on Attorney General Barr to resign'\\n 'FCA plant closure China supply issue causes Fiat Chrysler Serbia plant closure Auto News ET Auto URL'\\n 'The cost of dying How ike in cremation rates is changing the funeral industry'\\n 'Fossil fuel industry hosts EU presidency URL'\\n 'URL NASA Space Exploration and Astronomy News URL'\\n 'Half million Romanians want to stay in UK'\\n 'Canadians already quarantined on cruise ship in Japan to be isolated for another weeks at home'\\n 'Kosovo Parliament Not Informed on Signed Agreements with Serbia Says Speaker Osmani Exit Explaining Albania URL'\\n 'Mountain Zlatibor Serbia Photo of the Day Havana Times URL'\\n 'SpaceX Crew Dragon acecraft nears last parachute tests before astronaut launch debut URL'\\n 'With eye on moon NASA to seek new astronaut applicants in March'\\n 'Demonstrators gather at Confederation Bridge to back Wet suwet en hereditary chiefs'\\n 'Famed biologist Richard Dawkins arks Twitter row with eugenics would work for humans argument RT World News URL'\\n 'Serbia Natalija Kostic Gets Engaged to Boyfriend during WTA Thailand Open URL'\\n 'The Scotsman Scottish News URL'\\n 'Local news orts business politics entertainment travel restaurants and opinion for Seat URL'\\n 'RCMP mistakes stroke victim for drunk leaving him half paralyzed in jail cell for hours lawsuit says'\\n 'Medium Get smarter about what matters to you URL'\\n 'Copper wire thieves wreaking havoc on Seattle URL'\\n 'Michel proposes GNI percent for budget URL'\\n 'GM scraps historic Holden car brand in Australia BBC News URL'\\n 'This is How Society Dies URL'\\n 'Uganda Queen of Katwe star Nikita Pearl Waligwa dies aged BBC News URL'\\n 'Auditors Commission should update nuclear safety rules URL'\\n 'premier cancels controversial plan to close rural ERs overnight'\\n 'Heathrow diversion New York flight makes emergency landing and passenger detained MyLondon URL'\\n 'The New York Times Breaking News World News amp Multimedia URL'\\n 'MALCOLM Has anyone seen our Prime Minister True North URL'\\n 'Inside the meeting between Mohawks and Canada Indigenous services minister'\\n 'SETI search of interstellar Comet Borisov finds no sign of alien technosignatures'\\n 'Two injured in Moscow church knife attack URL'\\n 'Petr Pavlensky Russian activist girlfriend held over Macron ally sex video BBC News URL'\\n 'Serbia Honors Author Handke Amid Anger Over Milosevic Ties URL'\\n 'bne IntelliNews Fiat halts production in Serbian plant as coronavirus disrupts supply chains URL'\\n 'Petition update MEPs rally to support citizens rights post Brexit as our fight for an HASHTAG goes on URL'\\n 'Your Monday Briefing The New York Times URL'\\n 'Chaos at Heathrow Airport as technical issues cause mass disruption'\\n 'Secretary Michael Pompeo and Senegalese Foreign Minister Amadou Ba at Joint Press Availability United States URL'\\n 'The New York Review of Books URL'\\n 'Democrats fear rule of law crumbling under Trump'\\n 'Three Bright Planets Align In The Morning Sky'\\n 'Amid crime wave on Yakama Reservation confusion over checkerboard of jurisdictions URL'\\n 'Crossing the border to go to school in the US BBC News URL'\\n 'Egypt health ministry announces first confirmed coronavirus case URL'\\n 'Boris Johnson could rip up human rights to push through new terror law'\\n 'DROVER It time to regulate online pornography in Canada True North URL'\\n 'Washington Post Breaking News World US DC News amp Analysis The Washington Post URL'\\n 'Trudeau office won say if it recorded meeting with Iranian foreign minister'\\n 'NASA iconic Pale Blue Dot photo of Earth from ace just got st century makeover'\\n 'EU plan on AI new rules better taxes URL'\\n 'Secretary Michael Pompeo Meeting with Senegalese President Sall United States Department of State URL'\\n 'The United States and Angola Deepening an Important Strategic Partnership United States Department of State URL'\\n 'Mysterious fast radio bursts from deep ace repeat themselves every days'\\n 'Is Belgium heading for new elections URL'\\n 'French reforms Why France is resisting Macron push on pensions BBC News URL'\\n 'Brexit France warns UK of bitter trade negotiations BBC News URL'\\n 'The Celtic Barber Unpacking My Bottom Drawer URL'\\n 'Read The Liz Vicious Daily URL'\\n 'German president criticises US at Munich Conference URL'\\n 'Budget Zuckerberg Pelosi and Cayman Islands This WEEK URL'\\n 'Senate braces for fight over impeachment whistleblower testimony'\\n 'Serbia and Cuba strengthen relations URL'\\n 'Egg freezing What the success rate BBC News URL'\\n 'Star City adventure Take sneak peek into India first ace crew training in Russia RT World News URL'\\n 'little bit of excitement at no extra cost Sanders quips after TOPLESS anti dairy protesters steal show at Neva URL'\\n 'Lithuania National Day United States Department of State URL'\\n 'SpaceX delays launch of Starlink satellites due to rocket valve checks'\\n 'Blockade continues de ite modest progress made in talks between federal minister and Tyendinaga Mohawk'\\n 'EU parliament warns of data transfer risks due to UK immigration rules URL'\\n 'Candidates make electability arguments talk Bloomberg as focus turns to more diverse states'\\n 'Local news orts business politics entertainment travel restaurants and opinion for Seat URL'\\n 'bne IntelliNews Serbia and Kosovo agree to restore railway motorway links URL'\\n 'Blue Jays legend Tony Fernandez dies at from stroke kidney complications'\\n 'Munich Security Conference UK suffered because of its absence'\\n 'LIVE Starship Assembly at SpaceX Boca Chica Sunday Feb YouTube URL'\\n 'What the EU can do for South Sudan right now URL'\\n 'Solar Orbiter launches on historic mission to study the sun poles'\\n 'SpaceX hires former NASA human aceflight chief'\\n 'Secretary Michael Pompeo and Senegalese Minister of Economy Amadou Hott at Memoranda of Understanding Signing URL'\\n 'NASA has plan for yearly Artemis moon flights through The first one could fly in'\\n 'Federal government to bring home Canadians on board quarantined cruise ship'\\n 'cases of environmental dissenters being cancelled True North URL'\\n 'The Ethiopian migrants who make the de erate journey to Saudi Arabia via Yemen Reporters URL'\\n 'Kurti Government Didn Authorize Signing of Two Agreements with Serbia Exit Explaining Albania URL'\\n 'FUREY Majority of First Nations support Canadian energy True North URL'\\n 'The last best chance for Donbas and peace in Europe URL'\\n 'Mars breakthrough UK build plasma powered rocket could halve journey times to Red Planet'\\n 'Skylarks chamois to be protected in RO'\\n 'Scientists just watched newfound asteroid zoom by Earth Then they saw its moon'\\n 'When is the best time to visit Banff Lake Louise or Ja er'\\n 'Outrage as Downing Street adviser backs EUGENICS mandatory birth control and giving kids mind altering drugs RT URL'\\n 'Thought biathlon was boring Meet Dorothea Wierer the Italian star sending fans wild at the World Championsh URL'\\n 'Net payer countries push back on EU budget plans URL'\\n 'Hypnogoria HYPNOGORIA History of Horror Video Games Part URL']\",\n",
              "       \"['FBI Most Wanted Season Episode Hairtrigger Synopsis HASHTAG HASHTAG URL'\\n 'Station Season Episode House Where Nobody Lives Synopsis HASHTAG URL URL'\\n 'Chicago PD Season Episode Center Mass Synopsis HASHTAG URL URL'\\n 'HASHTAG Season Episode Ephemera Synopsis amp Promo URL URL'\\n 'Katy Keene Season Episode What Becomes of the Broken Hearted Synopsis HASHTAG URL URL'\\n 'Party of Five Season Episode Dos Dos Synopsis amp Promo HASHTAG URL URL'\\n 'The Magicians Season Episode Garden Variety Homicide Synopsis HASHTAG URL URL'\\n 'FBI Most Wanted Season Episode Invisible Synopsis amp Promo HASHTAG URL URL'\\n 'The Sinner Season Episode Part III Synopsis amp Promo HASHTAG URL URL'\\n 'Criminal Minds Series Finale Synopsis amp Promo HASHTAG URL URL'\\n 'Party of Five Season Episode Dos Dos Synopsis HASHTAG URL URL'\\n 'HASHTAG Season Episode Emergency Exit Synopsis URL URL'\\n 'The Outsider Season Episode Tear Drinker Synopsis HASHTAG URL URL'\\n 'Prodigal Son Season Episode Death Door Synopsis amp Promo HASHTAG URL URL'\\n 'Party of Five Season Episode Speak for Yourself Synopsis HASHTAG URL URL'\\n 'Lincoln Rhyme Season Episode Requiem Synopsis HASHTAG URL URL'\\n 'The Sinner Season Episode Part Synopsis HASHTAG URL URL'\\n 'Nancy Drew Season Episode The Sign of the Uninvited Guest Synopsis amp Promo HASHTAG URL'\\n 'The Outsider Season Episode Must Can Synopsis HASHTAG URL URL'\\n 'HASHTAG Season Episode Bullying Synopsis URL URL'\\n 'The Sinner Season Episode Part IV Synopsis HASHTAG URL URL'\\n 'HASHTAG Season Episode Windmill Acetone Celluloid Firing Pin Synopsis URL URL'\\n 'Criminal Minds Series Finale Synopsis HASHTAG URL URL'\\n 'HASHTAG Season Episode Grandparents Synopsis URL URL'\\n 'HASHTAG Season Episode Bad Guy Synopsis URL URL'\\n 'For Life Season Episode Promises Synopsis amp Promo HASHTAG URL URL'\\n 'Chicago Fire Season Episode Shut It Down Synopsis HASHTAG URL URL'\\n 'The Outsider Season Episode In the Pines In the Pines Synopsis HASHTAG URL URL'\\n 'Chicago Med Season Episode It may not be forever Synopsis HASHTAG URL URL'\\n 'Chicago Fire Season Episode Off the Grid Synopsis HASHTAG URL URL'\\n 'Lone Star Season Episode Bum Steer Synopsis HASHTAG URL URL'\\n 'Chicago Fire Season Episode Off the Grid Synopsis HASHTAG URL URL'\\n 'Katy Keene Season Episode You Can Hurry Love Synopsis HASHTAG URL URL'\\n 'Lone Star Season Episode Studs Synopsis HASHTAG URL URL'\\n 'For Life Season Episode Brother Keeper Synopsis HASHTAG URL URL'\\n 'The Sinner Season Episode Part Synopsis HASHTAG URL URL'\\n 'HASHTAG Season Episode Drink Me Synopsis amp Promo URL URL'\\n 'Legends of Tomorrow Season Episode Mortal Khanbat Synopsis HASHTAG URL URL'\\n 'FBI Most Wanted Season Episode Prophet Synopsis HASHTAG URL URL'\\n 'HASHTAG Season Episode Ephemera Synopsis URL URL'\\n 'Lone Star Season Episode Monster Inside Synopsis HASHTAG URL URL'\\n 'Katy Keene Season Episode Song for Winter Night Synopsis HASHTAG URL URL'\\n 'Lone Star Season Episode Friends Like These Synopsis amp Promo HASHTAG URL URL'\\n 'HASHTAG Season Episode Fire Ashes Legacy Phoenix Synopsis amp Promo URL URL'\\n 'Party of Five Season Episode Mexico Synopsis HASHTAG URL URL'\\n 'HASHTAG Season Episode Soccer Desi Merchant Titan Synopsis URL URL'\\n 'HASHTAG Season Episode Lonely Hearts Synopsis URL URL'\\n 'Briarpatch Season Episode Terrible Shocking Things Synopsis URL URL'\\n 'HASHTAG Season Episode Drink Me Synopsis URL URL'\\n 'The Outsider Season Episode Foxhead Synopsis HASHTAG URL URL'\\n 'HASHTAG Season Episode Breadknife Weather Synopsis URL URL'\\n 'HASHTAG Season Episode Red Cell Quantum Cold Committed Synopsis URL URL'\\n 'Criminal Minds Season Episode Family Tree Synopsis amp Promo HASHTAG URL URL'\\n 'Station Season Episode Eulogy Synopsis HASHTAG URL URL'\\n 'HASHTAG Season Episode Animus Synopsis URL URL'\\n 'Chicago PD Season Episode Burden of Truth Synopsis HASHTAG URL URL'\\n 'HASHTAG Season Episode Failing Synopsis URL URL'\\n 'HASHTAG Season Episode Bullying Synopsis URL URL'\\n 'HASHTAG Season Episode How to Get Away with Murder Synopsis amp Promo URL URL'\\n 'Legends of Tomorrow Season Episode Head of Her Time Synopsis HASHTAG URL URL'\\n 'HASHTAG Season Episode Kid Plane Cable Truck Synopsis amp Promo URL URL'\\n 'Legends of Tomorrow Season Episode Mr Parker Cul De Sac Synopsis HASHTAG URL'\\n 'HASHTAG Season Official Promo URL URL'\\n 'HASHTAG Season Episode Emergency Exit Synopsis amp Promo URL URL'\\n 'Nancy Drew Season Episode The Terror of Horseshoe Bay Synopsis HASHTAG URL URL'\\n 'Katy Keene Season Episode Here Comes the Sun Synopsis HASHTAG URL URL'\\n 'The Outsider Season Episode Tigers and Bears Synopsis HASHTAG URL URL'\\n 'Legends of Tomorrow Season Episode Head of Her Time Synopsis amp Promo HASHTAG URL'\\n 'FBI Most Wanted Season Episode Prophet Synopsis amp Promo HASHTAG URL URL'\\n 'HASHTAG Season Episode Back From the Future Part Two Synopsis amp Promo URL URL'\\n 'Legends of Tomorrow Season Episode Slay Anything Synopsis HASHTAG URL URL'\\n 'HASHTAG Season Episode Kid Plane Cable Truck Synopsis URL URL'\\n 'HASHTAG Season Episode How to Get Away with Murder Synopsis URL URL'\\n 'HASHTAG Season Episode Men of Honor Synopsis URL URL'\\n 'The Outsider Season Episode The One About the Yiddish Vampire Synopsis HASHTAG URL'\\n 'HASHTAG Season Episode It Super Life Synopsis amp Promo URL URL'\\n 'HASHTAG Season Episode It Super Life Synopsis URL URL'\\n 'The Magicians Season Episode Acting Dean Synopsis amp Promo HASHTAG URL URL'\\n 'Lincoln Rhyme Season Episode What Lies Beneath Synopsis HASHTAG URL URL'\\n 'Lincoln Rhyme Season Episode Til Death Do Us Part Synopsis amp Promo HASHTAG URL URL'\\n 'Motherland Fort Salem Season Promo HASHTAG URL URL'\\n 'HASHTAG Season Episode The Ides of March Synopsis URL URL'\\n 'The Sinner Season Episode Part III Synopsis HASHTAG URL URL'\\n 'Lone Star Season Episode Friends Like These Synopsis HASHTAG URL URL'\\n 'The Magicians Season Episode Oops Did It Again Synopsis HASHTAG URL URL'\\n 'HASHTAG Season Episode Dating Synopsis URL URL'\\n 'Criminal Minds Season Episode Rusty Synopsis HASHTAG URL URL'\\n 'Station Season Episode Into the Woods Synopsis HASHTAG URL URL'\\n 'The Magicians Season Episode Acting Dean Synopsis HASHTAG URL URL'\\n 'Criminal Minds Season Episode Family Tree Synopsis HASHTAG URL URL'\\n 'The Sinner Season Episode Part II Synopsis HASHTAG URL URL'\\n 'HASHTAG Season Episode Return Trip Synopsis URL URL'\\n 'Station Season Episode Ice Ice Baby Synopsis HASHTAG URL URL'\\n 'Lincoln Rhyme Season Episode Game On Synopsis HASHTAG URL URL'\\n 'Station Season Episode Into the Woods Synopsis amp Promo HASHTAG URL URL'\\n 'Chicago Med Season Episode Will Do No Harm Synopsis HASHTAG URL URL'\\n 'The Magicians Season Episode Oops Did It Again Synopsis amp Promo HASHTAG URL URL'\\n 'Party of Five Season Episode Patch Job Synopsis HASHTAG URL URL'\\n 'Katy Keene Season Episode What Becomes of the Broken Hearted Synopsis HASHTAG URL URL'\\n 'The Magicians Season Episode Cello Squirrel Daffodil Synopsis HASHTAG URL URL']\"],\n",
              "      dtype='<U11853')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DWfMmMBIjgDc"
      },
      "source": [
        "## Sentiment_Polarity\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8OKKEpD-kGt_"
      },
      "source": [
        "sid = SentimentIntensityAnalyzer()\n",
        "def compute_sentiment_features(tweets):\n",
        "  \"\"\"\n",
        "  Arguments:\n",
        "    tweets - array of tweets\n",
        "  \"\"\"\n",
        "  polarity = []\n",
        "  for tweet in tweets:\n",
        "    scores = sid.polarity_scores(tweet)\n",
        "    polarity.append([scores['neg']])\n",
        "  return np.mean(polarity, axis=0), np.std(polarity, axis=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iew_5sVKk87o"
      },
      "source": [
        "X_polarity = np.array([compute_sentiment_features(x_tweet) for x_tweet in X_tweets]).reshape(300, -1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "crmZKa9_oHdK",
        "outputId": "a699e436-5788-437c-9924-9986aebba0cd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "X_polarity.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(300, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bYkGWltjBiTg"
      },
      "source": [
        "## Pos_Tagging"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v_G48UbuJnMk"
      },
      "source": [
        "def get_pos_features(pos_tags):\n",
        "  \"\"\"\n",
        "  Arguments:\n",
        "    pos_tags - array of pos tagged words\n",
        "  Returns:\n",
        "    PRP counts\n",
        "  \"\"\"\n",
        "  count_prp = 0\n",
        "  for pos_tag in pos_tags:\n",
        "    tag = pos_tag[1]\n",
        "    if tag == 'PRP':\n",
        "      count_prp += 1\n",
        "\n",
        "  return np.array([count_prp])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "99KdVz7iDcws"
      },
      "source": [
        "X_pos = np.array([np.array(get_tweets_pos_tags(x)) for x in X])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rVXjIVRwJIWT"
      },
      "source": [
        "X_pos_counts = np.array([get_pos_features(x_pos) for x_pos in X_pos])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lFQ2ZD4Ds_x8",
        "outputId": "fdb3b862-85ec-4415-a282-a7fa5342b0f0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "X_pos_counts[:10]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 7],\n",
              "       [ 7],\n",
              "       [25],\n",
              "       [63],\n",
              "       [20],\n",
              "       [30],\n",
              "       [ 2],\n",
              "       [36],\n",
              "       [ 3],\n",
              "       [45]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fCNZ244v-OUJ"
      },
      "source": [
        "# Models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lAgCs1RcJsiB"
      },
      "source": [
        "def get_tfidf_vectorizer(language='en'):\n",
        "  if language == 'en':\n",
        "    language_stopwords = 'english'\n",
        "    max_df = .9\n",
        "    n_gram_range = (1,1)\n",
        "  else:\n",
        "    language_stopwords = 'spanish'\n",
        "    max_df = .7\n",
        "    n_gram_range = (1,2)\n",
        "\n",
        "  return TfidfVectorizer(max_features=500, min_df=5, max_df=max_df, ngram_range=n_gram_range, stop_words=stopwords.words(language_stopwords))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a8hMxGTQ-PG8"
      },
      "source": [
        "def get_random_forest_classifier_model(n_estimators=500):\n",
        "  rf_model = RandomForestClassifier(n_estimators=n_estimators, random_state=42)\n",
        "  return rf_model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xT6BIE6SMMIj"
      },
      "source": [
        "def get_gradient_boosting_classifier_model(n_estimators=500):\n",
        "  gb_model = GradientBoostingClassifier(n_estimators=n_estimators, random_state=42)\n",
        "  return gb_model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "62ebCRE19QsP"
      },
      "source": [
        "def get_dense_model(input_shape):\n",
        "  model = tf.keras.Sequential()\n",
        "  model.add(tf.keras.layers.Dense(64, activation='relu', input_shape=(input_shape, )))\n",
        "  model.add(tf.keras.layers.Dropout(.2))\n",
        "  model.add(tf.keras.layers.Dense(32, activation='relu'))\n",
        "  model.add(tf.keras.layers.Dense(1, activation='sigmoid'))\n",
        "\n",
        "  model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wjTsZ-8p-ZJh"
      },
      "source": [
        "@tf.function\n",
        "def map_output(x):\n",
        "  if x > .5:\n",
        "    1.0\n",
        "  else:\n",
        "    0.0\n",
        "\n",
        "def get_doc2vec_model():\n",
        "  embed_model = 'https://tfhub.dev/google/tf2-preview/gnews-swivel-20dim/1'\n",
        "  hub_layer = hub.KerasLayer(embed_model, output_shape=(20), dtype=tf.string, input_shape=(), trainable=True)\n",
        "  model = tf.keras.Sequential()\n",
        "  model.add(hub_layer)\n",
        "  model.add(tf.keras.layers.Dense(64, activation='relu'))\n",
        "  model.add(tf.keras.layers.Dropout(.3))\n",
        "  model.add(tf.keras.layers.Dense(32, activation='relu'))\n",
        "  model.add(tf.keras.layers.Dense(1, activation='sigmoid'))\n",
        "\n",
        "  model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QPMuC0gM9EKg"
      },
      "source": [
        "# Manual_Encoding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J5qCgtpC9GN2"
      },
      "source": [
        "X_manual = np.hstack((X_pos_counts, X_extra, X_polarity)).astype(np.float32)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZhaihldY9ehT",
        "outputId": "f594a0bf-acae-44d7-fc00-3679f1ed270e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "X_manual[:2]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 7.        , 71.93      , 23.160852  ,  0.07948   ,  0.1348088 ],\n",
              "       [ 7.        , 65.05      , 10.464583  ,  0.08328   ,  0.12664218]],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M7fk-3C4SgKB"
      },
      "source": [
        "## Manual_Encoding_Gradient_Boosting"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LTsniFaPSi5f",
        "outputId": "5cd7ec77-d7ed-4b1f-d641-cafaa00168d2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        }
      },
      "source": [
        "skf = StratifiedKFold(5, random_state=42)\n",
        "history = []\n",
        "for train_split, test_split in skf.split(X_manual, y):\n",
        "  X_train, X_test, y_train, y_test = X_manual[train_split], X_manual[test_split], y[train_split], y[test_split]\n",
        "\n",
        "  gb_classifier_model = get_gradient_boosting_classifier_model()\n",
        "  gb_classifier_model.fit(X_train, y_train)\n",
        "\n",
        "  y_pred = gb_classifier_model.predict(X_test)\n",
        "\n",
        "  accuracy = accuracy_score(y_test, y_pred)\n",
        "  history.append(accuracy)\n",
        "\n",
        "  print(\"Accuracy: {}%\".format(accuracy))\n",
        "print(\"Mean Accuracy: {}%\".format(np.mean(history)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_split.py:296: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
            "  FutureWarning\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 0.6666666666666666%\n",
            "Accuracy: 0.65%\n",
            "Accuracy: 0.5833333333333334%\n",
            "Accuracy: 0.6%\n",
            "Accuracy: 0.6833333333333333%\n",
            "Mean Accuracy: 0.6366666666666667%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r44JR4UJSpl7"
      },
      "source": [
        "## Manual_Encoding_Random_Forest"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KBg_H7ti9qpk",
        "outputId": "b5e247c0-f68a-4435-e657-e582576ab71f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        }
      },
      "source": [
        "skf = StratifiedKFold(5, random_state=42)\n",
        "history = []\n",
        "for train_split, test_split in skf.split(X_manual, y):\n",
        "  X_train, X_test, y_train, y_test = X_manual[train_split], X_manual[test_split], y[train_split], y[test_split]\n",
        "\n",
        "  rf_classifier_model = get_random_forest_classifier_model()\n",
        "  rf_classifier_model.fit(X_train, y_train)\n",
        "\n",
        "  y_pred = rf_classifier_model.predict(X_test)\n",
        "\n",
        "  accuracy = accuracy_score(y_test, y_pred)\n",
        "  history.append(accuracy)\n",
        "\n",
        "  print(\"Accuracy: {}%\".format(accuracy))\n",
        "print(\"Mean Accuracy: {}%\".format(np.mean(history)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_split.py:296: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
            "  FutureWarning\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 0.6333333333333333%\n",
            "Accuracy: 0.6333333333333333%\n",
            "Accuracy: 0.6%\n",
            "Accuracy: 0.5833333333333334%\n",
            "Accuracy: 0.7%\n",
            "Mean Accuracy: 0.6300000000000001%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tuTTVgs7L9Dd"
      },
      "source": [
        "# TFIDF_Encoding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f0Y9ARm6MAHa"
      },
      "source": [
        "def tfidf_features(text, training=True):\n",
        "  \"\"\"\n",
        "  Arguments:\n",
        "    text - string\n",
        "    training - flag\n",
        "  Returns:\n",
        "    tfidf feature matrix\n",
        "  \"\"\"\n",
        "  if training:\n",
        "      x = tfidf.fit_transform(text)\n",
        "  else:\n",
        "      x = tfidf.transform(text)\n",
        "  x = x.astype('float32')\n",
        "  return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GuM4rEOrVoCw"
      },
      "source": [
        "## CHI2_Feature_Selection\n",
        "This section is not being used, as it doesn't contribute to the accuracy of the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xPOhyQYdVsZZ"
      },
      "source": [
        "def chi2_features_select(X_train, X_test, y_train, k=10):\n",
        "  \"\"\"\n",
        "  Arguments:\n",
        "    X - data\n",
        "    y - labels\n",
        "    n - number of features to select\n",
        "  Returns:\n",
        "    dataset containing n best features\n",
        "  \"\"\"\n",
        "  ch2 = SelectKBest(score_func=chi2, k=k)\n",
        "  X_train = ch2.fit_transform(X_train, y_train)\n",
        "  X_test = ch2.transform(X_test)\n",
        "  return X_train, X_test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x-wDX8XicTQ4"
      },
      "source": [
        "def tfidf_features_best_plot(X, y, k=10):\n",
        "  \"\"\"\n",
        "  Arguments:\n",
        "    X_train - datasets\n",
        "    y_train - labels\n",
        "    k - number of features to plot\n",
        "  Returns:\n",
        "    plots data\n",
        "  \"\"\"\n",
        "\n",
        "  chi2score = chi2(X, y)[0]\n",
        "  plt.figure(figsize=(15,10))\n",
        "  wscores = list(zip(tfidf.get_feature_names(), chi2score))\n",
        "  wchi2 = sorted(wscores, key=lambda x:x[1])\n",
        "  topchi2 = list(zip(*wchi2[-k:]))\n",
        "  x = range(len(topchi2[1]))\n",
        "  labels = topchi2[0]\n",
        "  plt.barh(x,topchi2[1], align='center', alpha=0.2)\n",
        "  plt.plot(topchi2[1], x, '-o', markersize=5, alpha=0.8)\n",
        "  plt.yticks(x, labels)\n",
        "  plt.xlabel('$\\chi^2$')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iJmoeBVWPsBy"
      },
      "source": [
        "## TFIDF_Gradient_Boosting\n",
        "- gives the best results for TFIDF proccessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MlyTBNKLPwGi",
        "outputId": "bdca3797-f510-407b-a06a-3e7729518372",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        }
      },
      "source": [
        "skf = StratifiedKFold(5, random_state=42)\n",
        "history = []\n",
        "n_best_words= 50\n",
        "for train_split, test_split in skf.split(X, y):\n",
        "  X_train, X_test, y_train, y_test = X[train_split], X[test_split], y[train_split], y[test_split]\n",
        "\n",
        "  tfidf = get_tfidf_vectorizer(lang)\n",
        "  X_train_feat = tfidf_features(X_train).todense()\n",
        "  X_test_feat = tfidf_features(X_test, training=False).todense()\n",
        "\n",
        "  gb_classifier_model = get_gradient_boosting_classifier_model()\n",
        "  gb_classifier_model.fit(X_train_feat, y_train)\n",
        "  y_pred = gb_classifier_model.predict(X_test_feat)\n",
        "\n",
        "  accuracy = accuracy_score(y_test, y_pred)\n",
        "  history.append(accuracy)\n",
        "\n",
        "  print(\"Accuracy: {}%\".format(accuracy))\n",
        "print(\"Mean Accuracy: {}%\".format(np.mean(history)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_split.py:296: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
            "  FutureWarning\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 0.6833333333333333%\n",
            "Accuracy: 0.7166666666666667%\n",
            "Accuracy: 0.7166666666666667%\n",
            "Accuracy: 0.7666666666666667%\n",
            "Accuracy: 0.8166666666666667%\n",
            "Mean Accuracy: 0.74%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3axD009tRjAw"
      },
      "source": [
        "## TFIDF_Random_Forest"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_jXkRXuBAwVC",
        "outputId": "c6387eed-6a97-4528-a5f5-5612893481eb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        }
      },
      "source": [
        "skf = StratifiedKFold(5, random_state=42)\n",
        "history = []\n",
        "n_best_words= 50\n",
        "for train_split, test_split in skf.split(X, y):\n",
        "  X_train, X_test, y_train, y_test = X[train_split], X[test_split], y[train_split], y[test_split]\n",
        "\n",
        "  tfidf = get_tfidf_vectorizer(lang)\n",
        "  X_train_feat = tfidf_features(X_train).todense()\n",
        "  X_test_feat = tfidf_features(X_test, training=False).todense()\n",
        "\n",
        "  rf_classifier_model = get_random_forest_classifier_model()\n",
        "  rf_classifier_model.fit(X_train_feat, y_train)\n",
        "  y_pred = rf_classifier_model.predict(X_test_feat)\n",
        "\n",
        "  accuracy = accuracy_score(y_test, y_pred)\n",
        "  history.append(accuracy)\n",
        "\n",
        "  print(\"Accuracy: {}%\".format(accuracy))\n",
        "print(\"Mean Accuracy: {}%\".format(np.mean(history)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_split.py:296: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
            "  FutureWarning\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 0.6833333333333333%\n",
            "Accuracy: 0.6833333333333333%\n",
            "Accuracy: 0.6666666666666666%\n",
            "Accuracy: 0.7%\n",
            "Accuracy: 0.7166666666666667%\n",
            "Mean Accuracy: 0.6900000000000001%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y_uPs6PC98Q5"
      },
      "source": [
        "## TFIDF_Dense"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JCK49tX797jg",
        "outputId": "3bedd734-7c61-4892-e464-077c86f71595",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        }
      },
      "source": [
        "skf = StratifiedKFold(5, random_state=42)\n",
        "history = []\n",
        "n_best_words= 50\n",
        "for train_split, test_split in skf.split(X, y):\n",
        "  X_train, X_test, y_train, y_test = X[train_split], X[test_split], y[train_split], y[test_split]\n",
        "\n",
        "  tfidf = get_tfidf_vectorizer(lang)\n",
        "  X_train_feat = tfidf_features(X_train).todense()\n",
        "  X_test_feat = tfidf_features(X_test, training=False).todense()\n",
        "\n",
        "  dense = get_dense_model(X_train_feat.shape[1])\n",
        "  dense.fit(X_train_feat, y_train, batch_size=10, epochs=50, verbose=None)\n",
        "  y_pred = dense.predict_classes(X_test_feat)\n",
        "\n",
        "  accuracy = accuracy_score(y_test, y_pred)\n",
        "  history.append(accuracy)\n",
        "\n",
        "  print(\"Accuracy: {}%\".format(accuracy))\n",
        "print(\"Mean Accuracy: {}%\".format(np.mean(history)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_split.py:296: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
            "  FutureWarning\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-67-527dffaf866e>:13: Sequential.predict_classes (from tensorflow.python.keras.engine.sequential) is deprecated and will be removed after 2021-01-01.\n",
            "Instructions for updating:\n",
            "Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
            "Accuracy: 0.6166666666666667%\n",
            "Accuracy: 0.65%\n",
            "Accuracy: 0.7833333333333333%\n",
            "Accuracy: 0.75%\n",
            "Accuracy: 0.6666666666666666%\n",
            "Mean Accuracy: 0.6933333333333332%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xM0o_9GGTrQW"
      },
      "source": [
        "## TFIDF_Polarity_Feature_Fusion_Random_Forest\n",
        "- combining polarity with TFIDF, slightly improves the accuracy.\n",
        "- we might want to discard this section also"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CinjqDpbSPKb",
        "outputId": "978382b5-8066-46de-80e1-73deb69257bf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        }
      },
      "source": [
        "skf = StratifiedKFold(5, random_state=42)\n",
        "history = []\n",
        "n_best_words= 50\n",
        "for train_split, test_split in skf.split(X, y):\n",
        "  X_train, X_test, y_train, y_test = X[train_split], X[test_split], y[train_split], y[test_split]\n",
        "  # X_pos_counts_train, X_pos_counts_test = X_pos_counts[train_split], X_pos_counts[test_split]\n",
        "  X_polarity_norm = X_polarity / np.amax(X_polarity)\n",
        "  X_polarity_train, X_polarity_test = X_polarity_norm[train_split], X_polarity_norm[test_split]\n",
        "\n",
        "  tfidf = get_tfidf_vectorizer(lang)\n",
        "  X_train_feat = tfidf_features(X_train).todense()\n",
        "  X_test_feat = tfidf_features(X_test, training=False).todense()\n",
        "\n",
        "  # Add POS Features\n",
        "  # X_train_feat = np.hstack((X_train_feat, X_pos_counts_train))\n",
        "  # X_test_feat = np.hstack((X_test_feat, X_pos_counts_test))\n",
        "\n",
        "  # Add Extra Features\n",
        "  # X_train_feat = np.hstack((X_train_feat, X_extra_train))\n",
        "  # X_test_feat = np.hstack((X_test_feat, X_extra_test))\n",
        "\n",
        "  # Add Polarity Features\n",
        "  X_train_feat = np.hstack((X_train_feat, X_polarity_train))\n",
        "  X_test_feat = np.hstack((X_test_feat, X_polarity_test))\n",
        "\n",
        "  rf_classifier_model = get_random_forest_classifier_model()\n",
        "  rf_classifier_model.fit(X_train_feat, y_train)\n",
        "  y_pred = rf_classifier_model.predict(X_test_feat)\n",
        "\n",
        "  accuracy = accuracy_score(y_test, y_pred)\n",
        "  history.append(accuracy)\n",
        "\n",
        "  print(\"Accuracy: {}\".format(accuracy))\n",
        "print(\"Mean Accuracy: {}\".format(np.mean(history)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_split.py:296: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
            "  FutureWarning\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 0.7666666666666667\n",
            "Accuracy: 0.6666666666666666\n",
            "Accuracy: 0.6833333333333333\n",
            "Accuracy: 0.7166666666666667\n",
            "Accuracy: 0.7333333333333333\n",
            "Mean Accuracy: 0.7133333333333334\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qJ04ucFaqg-5"
      },
      "source": [
        "## TFIDF_Polarity_Feature_Fusion_Gradient_Boosting"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hA82zDghqhVQ",
        "outputId": "ca8c0888-d5a1-40bc-f5fe-03c0e5248638",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "skf = StratifiedKFold(5, shuffle=False)\n",
        "history = []\n",
        "n_best_words= 50\n",
        "for train_split, test_split in skf.split(X, y):\n",
        "  X_train, X_test, y_train, y_test = X[train_split], X[test_split], y[train_split], y[test_split]\n",
        "  # X_pos_counts_train, X_pos_counts_test = X_pos_counts[train_split], X_pos_counts[test_split]\n",
        "  X_polarity_norm = X_polarity / np.amax(X_polarity)\n",
        "  X_polarity_train, X_polarity_test = X_polarity_norm[train_split], X_polarity_norm[test_split]\n",
        "\n",
        "  tfidf = get_tfidf_vectorizer(lang)\n",
        "  X_train_feat = tfidf_features(X_train).todense()\n",
        "  X_test_feat = tfidf_features(X_test, training=False).todense()\n",
        "\n",
        "  # Add Polarity Features\n",
        "  X_train_feat = np.hstack((X_train_feat, X_polarity_train))\n",
        "  X_test_feat = np.hstack((X_test_feat, X_polarity_test))\n",
        "\n",
        "  rf_classifier_model = get_gradient_boosting_classifier_model()\n",
        "  rf_classifier_model.fit(X_train_feat, y_train)\n",
        "  y_pred = rf_classifier_model.predict(X_test_feat)\n",
        "\n",
        "  accuracy = accuracy_score(y_test, y_pred)\n",
        "  history.append(accuracy)\n",
        "\n",
        "  print(\"Accuracy: {}\".format(accuracy))\n",
        "print(\"Mean Accuracy: {}\".format(np.mean(history)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 0.7\n",
            "Accuracy: 0.7\n",
            "Accuracy: 0.7\n",
            "Accuracy: 0.8166666666666667\n",
            "Accuracy: 0.8166666666666667\n",
            "Mean Accuracy: 0.7466666666666665\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HU8NSSen0k5y"
      },
      "source": [
        "# Doc2Vec_Embedding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xHA91sIx9xCB",
        "outputId": "961eadf3-7caa-47e5-ce23-f77a2f1027db",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "skf = StratifiedKFold(5, shuffle=False)\n",
        "history = []\n",
        "evaluate = []\n",
        "for train_split, test_split in skf.split(X, y):\n",
        "  X_train, X_test, y_train, y_test = X[train_split], X[test_split], y[train_split], y[test_split]\n",
        "  model = get_doc2vec_model()\n",
        "  h = model.fit(X_train, y_train, batch_size=10, epochs=15, verbose=None)\n",
        "  y_pred = model.predict_classes(X_test)\n",
        "  accuracy = accuracy_score(y_test, y_pred)\n",
        "  history.append(accuracy)\n",
        "\n",
        "  print('Accuracy: {}'.format(accuracy))\n",
        "print('Mean Accuracy: {}'.format(np.mean(history)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 0.5666666666666667\n",
            "Accuracy: 0.7166666666666667\n",
            "Accuracy: 0.65\n",
            "Accuracy: 0.7\n",
            "Accuracy: 0.6166666666666667\n",
            "Mean Accuracy: 0.6499999999999999\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZNSaXp6BFd4g",
        "outputId": "ff69faf6-a8bf-4159-88ef-0458622b5e9e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "for e in evaluate:\n",
        "  print(\"Test loss: {} | Test accuracy: {}\".format(e[0], e[1]))\n",
        "  print(e)\n",
        "print(np.mean(evaluate, axis=0))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "nan\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/numpy/core/fromnumeric.py:3335: RuntimeWarning: Mean of empty slice.\n",
            "  out=out, **kwargs)\n",
            "/usr/local/lib/python3.6/dist-packages/numpy/core/_methods.py:161: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dxxwHBY6sIRj"
      },
      "source": [
        "# Late Feature Fusion"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u1yW4ctatee9"
      },
      "source": [
        "def compute_proba_to_pred(y_1, y_2):\n",
        "  \"\"\"\n",
        "  Arguments:\n",
        "    y_1 - 1st model probabilities for classes\n",
        "    y_2 - 2nd model probabilities for classes\n",
        "  Returns:\n",
        "    0, 1 classes according to probabilities\n",
        "  \"\"\"\n",
        "  y_merged = (y_1 + y_2) / 2\n",
        "  return np.argmax(y_merged, axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_irsc2zBvxYr"
      },
      "source": [
        "## 2 x Random Forest"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VvP7EwCosKZK",
        "outputId": "e0617ef6-2d2d-4607-8f23-42dc43cbce1b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "skf = StratifiedKFold(5, shuffle=False)\n",
        "history = []\n",
        "n_best_words= 50\n",
        "for train_split, test_split in skf.split(X, y):\n",
        "  y_train, y_test = y[train_split], y[test_split]\n",
        "  X_train, X_test = X[train_split], X[test_split]\n",
        "  X_train_manual, X_test_manual = X_manual[train_split], X_manual[test_split]\n",
        "\n",
        "  tfidf = get_tfidf_vectorizer(lang)\n",
        "  X_train_feat = tfidf_features(X_train).todense()\n",
        "  X_test_feat = tfidf_features(X_test, training=False).todense()\n",
        "\n",
        "\n",
        "  rf_classifier_model_tfidf = get_random_forest_classifier_model()\n",
        "  rf_classifier_model_manual = get_random_forest_classifier_model()\n",
        "\n",
        "  rf_classifier_model_tfidf.fit(X_train_feat, y_train)\n",
        "  rf_classifier_model_manual.fit(X_train_manual, y_train)\n",
        "\n",
        "  y_pred_tfidf = rf_classifier_model_tfidf.predict_proba(X_test_feat)\n",
        "  y_pred_manual = rf_classifier_model_manual.predict_proba(X_test_manual)\n",
        "\n",
        "  y_pred = compute_proba_to_pred(y_pred_tfidf, y_pred_manual)\n",
        "\n",
        "  accuracy = accuracy_score(y_test, y_pred)\n",
        "  history.append(accuracy)\n",
        "\n",
        "  print(\"Accuracy: {}%\".format(accuracy))\n",
        "print(\"Mean Accuracy: {}%\".format(np.mean(history)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 0.7166666666666667%\n",
            "Accuracy: 0.6%\n",
            "Accuracy: 0.6666666666666666%\n",
            "Accuracy: 0.7%\n",
            "Accuracy: 0.65%\n",
            "Mean Accuracy: 0.6666666666666667%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ueMGaSo4v0Uf"
      },
      "source": [
        "## 2 x Gradient Boosting"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o9JJ5eEhvtkf",
        "outputId": "5e4f0c27-2bcc-4bbc-d137-e5687dae4edc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "skf = StratifiedKFold(5, shuffle=False)\n",
        "history = []\n",
        "n_best_words= 50\n",
        "for train_split, test_split in skf.split(X, y):\n",
        "  y_train, y_test = y[train_split], y[test_split]\n",
        "  X_train, X_test = X[train_split], X[test_split]\n",
        "  X_train_manual, X_test_manual = X_manual[train_split], X_manual[test_split]\n",
        "\n",
        "  # tfidf = TfidfVectorizer(max_features=500, min_df=5, max_df=.7, ngram_range=(1,1), stop_words=stopwords.words('english'))\n",
        "  tfidf = get_tfidf_vectorizer(lang)\n",
        "  X_train_feat = tfidf_features(X_train).todense()\n",
        "  X_test_feat = tfidf_features(X_test, training=False).todense()\n",
        "\n",
        "\n",
        "  gb_classifier_model_tfidf = get_gradient_boosting_classifier_model()\n",
        "  gb_classifier_model_manual = get_gradient_boosting_classifier_model()\n",
        "\n",
        "  gb_classifier_model_tfidf.fit(X_train_feat, y_train)\n",
        "  gb_classifier_model_manual.fit(X_train_manual, y_train)\n",
        "\n",
        "  y_pred_tfidf = gb_classifier_model_tfidf.predict_proba(X_test_feat)\n",
        "  y_pred_manual = gb_classifier_model_manual.predict_proba(X_test_manual)\n",
        "\n",
        "  y_pred = compute_proba_to_pred(y_pred_tfidf, y_pred_manual)\n",
        "\n",
        "  accuracy = accuracy_score(y_test, y_pred)\n",
        "  history.append(accuracy)\n",
        "\n",
        "  print(\"Accuracy: {}%\".format(accuracy))\n",
        "print(\"Mean Accuracy: {}%\".format(np.mean(history)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 0.75%\n",
            "Accuracy: 0.7%\n",
            "Accuracy: 0.6%\n",
            "Accuracy: 0.7166666666666667%\n",
            "Accuracy: 0.7333333333333333%\n",
            "Mean Accuracy: 0.7%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q-ZUGZ1pv3r0"
      },
      "source": [
        "## Gradient Boosting & Random Forest"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pz4FRObdvAJZ",
        "outputId": "928a1eca-b9cd-4f0e-e616-79bf4515e515",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "skf = StratifiedKFold(5, shuffle=False)\n",
        "history = []\n",
        "n_best_words= 50\n",
        "for train_split, test_split in skf.split(X, y):\n",
        "  y_train, y_test = y[train_split], y[test_split]\n",
        "  X_train, X_test = X[train_split], X[test_split]\n",
        "  X_train_manual, X_test_manual = X_manual[train_split], X_manual[test_split]\n",
        "\n",
        "  # tfidf = TfidfVectorizer(max_features=500, min_df=5, max_df=.7, ngram_range=(1,1), stop_words=stopwords.words('english'))\n",
        "  tfidf = get_tfidf_vectorizer(lang)\n",
        "  X_train_feat = tfidf_features(X_train).todense()\n",
        "  X_test_feat = tfidf_features(X_test, training=False).todense()\n",
        "\n",
        "\n",
        "  gb_classifier_model_tfidf = get_gradient_boosting_classifier_model()\n",
        "  rf_classifier_model_manual = get_random_forest_classifier_model()\n",
        "\n",
        "  gb_classifier_model_tfidf.fit(X_train_feat, y_train)\n",
        "  rf_classifier_model_manual.fit(X_train_manual, y_train)\n",
        "\n",
        "  y_pred_tfidf = gb_classifier_model_tfidf.predict_proba(X_test_feat)\n",
        "  y_pred_manual = rf_classifier_model_manual.predict_proba(X_test_manual)\n",
        "\n",
        "  y_pred = compute_proba_to_pred(y_pred_tfidf, y_pred_manual)\n",
        "\n",
        "  accuracy = accuracy_score(y_test, y_pred)\n",
        "  history.append(accuracy)\n",
        "\n",
        "  print(\"Accuracy: {}%\".format(accuracy))\n",
        "print(\"Mean Accuracy: {}%\".format(np.mean(history)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 0.7166666666666667%\n",
            "Accuracy: 0.75%\n",
            "Accuracy: 0.6833333333333333%\n",
            "Accuracy: 0.7833333333333333%\n",
            "Accuracy: 0.8333333333333334%\n",
            "Mean Accuracy: 0.7533333333333334%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S43zdXAJveV9"
      },
      "source": [
        "# Dummy_Classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w_1cfyGzvhl8",
        "outputId": "2d296ab2-efc9-4155-f80d-c64b74dae666",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "skf = StratifiedKFold(n_splits=5)\n",
        "\n",
        "for train_index, test_index in skf.split(X, y):\n",
        "  X_train, X_test = X_extra[train_index], X_extra[test_index]\n",
        "  y_train, y_test = y[train_index], y[test_index]\n",
        "\n",
        "  dummy_clf = DummyClassifier(strategy=\"most_frequent\")\n",
        "  dummy_clf.fit(X_train, y_train)\n",
        "  y_pred = dummy_clf.predict(X_test)\n",
        "  print(\"Dummy_Classifier:\", accuracy_score(y_test,y_pred))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Dummy_Classifier: 0.5\n",
            "Dummy_Classifier: 0.5\n",
            "Dummy_Classifier: 0.5\n",
            "Dummy_Classifier: 0.5\n",
            "Dummy_Classifier: 0.5\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}